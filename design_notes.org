* treeano - general
- architecture as data
  - the architecture of a single model should at every point be serializable and deserializable to the same model
- parameterization should be recursive
  - eg inner parameterization inherit outer parameterization unless explicitly overwritten
    - maybe: parameterization such as update strategy and initialization
  - use this for things like dropout
- shape must be knowable statically, at least for a fraction of the network
  - before learned weight initialization
    - eg. so that fully connected layers know their size
  - not all layers require shape
    - eg. conv/maxpool/spatial pyramid pooling
    - eg. if there is a spatial pyramid pooling layer, don't need to know shapes of conv layers
- all nodes should behave like data and only data
  - the interface should be what data it contains
  - possibly lazy data, though
- serialization
  - model architecture should be serialized in human-readable / edittable format
    - eg. yaml
    - being able to be serialized to json is probably a pretty safe format
      - though not necessarily serialized to json
  - model weights should be in some agnostic key-value store format
    - a similar architecture should be able to read in weights perfectly
    - path -> np.array
  - should be possible to share weights via specifying a similar architecture
    - since the layer names are absolutely critical to what "similar" means, it seems safe to assume that this sharing can come of the form of converting the other net into this key->value form and having the new net simply read from this blob
  - all layers can specify how they should be serialized (as data)
- input parameters
  - assumption: local networks (local = created together / close together) will have similar parameters
  - thus we can have local "inheritance" of parameters
    - eg. outer layer has an immutable dict of parameters, inner layer overwrites them when it has a parameter override, more inner layers can read from parameters with a key
    - this requires non-ambiguous keys
      - ie. 2 layers shouldn't have the same key mean different things
- need metadata on weight parameters
  - still need to specify backprop-able params, since the gradient needs to be calculated
  - still need to specify non-bias params, for regularization?
    - not necessarily, if the layer knows how to handle it's own parameters
    - this makes it easier if there is a large number of layers expected to be handle the same way
    - "the expression problem"
      - you might add a new layer that would want to benefit from all the regularization
      - you might add new regularization that would wnat to benefit from all layers
      - what commonality can we extract from this?
        - different parameters can behave the same way
        - eg. bias / inputweights
          - makes sense to have an "escape hatch" where things can work if not fitting within a mold
  - parameters should have tagging
    - to work with multiple kinds of regularization
- question: should all nodes have a unique name?
  - pros of unique name
    - don't need separate concepts for unique / non-unique
      - and some names do need to be unique (for initialization between networks)
  - cons
    - conceptually unnecessary, as long as they have a unique path
      - eg. don't need to name "convpoolstack_pool" when "pool" has parent "convpoolstack"
        - this would also be DRY-er and make the architectures more human readable
  - conclusion: just go with everything having a unique name
    - this should be easier to understand - and the downsides aren't that bad
- question: should hyperparameters have global default values
  - eg. shared initialization (create the var)
  - eg. weight initialization (0s)
  - answer: see "question: should parameters and shared variables have different initializations?"
- question: should parameters and shared variables have different initializations?
  - pros of different:
    - they are 2 very different things, no reason to have one know about the other
      - eg. Uniform initialization shouldn't have to know how to create a shared variable
    - if they were the same, and there was a subnetwork with different initialization, that subnetwork couldn't be initialized with shared variables from another network
      - this means that there must be a mechanism by which the shared initialization can overwrite that initialization
  - cons of different:
    - this is a purely theano-level concern, thus a conceptual network shouldn't require it
    - when using shared variables from a different network, you probably don't want to re-initialize
  - conclusion:
    - should be different
      - and a weight initialization node should look up the tree for a hyperparameter on shared initialization
    - weight initialization should have a default shared initialization
      - thus no global shared initialization should be needed
    - weight initialization and shared variable creation should happen at the same time, so that weight initialization knows now to overwrite the values in a shared variable
- should lifecycle methods (init_state, init_shared, init_values, and compute) be separate?
  - pros of separation
    - easier to do special schemes like loading existing network
    - may allow input layers to be partially initialized before initializing
  - cons
    - more boilerplate
    - somewhat more elegant to define everything in a single function
      - might not even need laziness
  - misc
    - seems unlikely that there would be a good use for having partially initialized layers
  - thought: init_state is different from the others - since initializing the variables can be lazy
    - alternative: pre_compute and post_compute steps for pre-order and post-order traversal
    - pros of separating only init_state
      - if they happen all at once, some nodes would need a pre-order traversal (eg. an initialization node that creates a stateful initializer), while pretty much all nodes need a post-order traversal (to specify output)
  - conclusion:
    - separate init_state, but have a single compute step which:
      - creates shared variables (parameters)
      - creates outputs
      - sets initial values of shared variables (parameters)
- using networkx to represent the graph
  - pros
    - a bunch of stuff for free
      - make it easy to look for ancestors, etc.
      - topological sort
      - make cute diagram of an architecture
  - cons
    - extra dependency
- should architecture nodes be separate from state nodes?
  - they conceptually serve 2 very different purposes
  - but there implementations are linked together
    - ie. the data in an architecture node is used for a state node
  - separating them would require additional verbosity to combine them together
  - conclusion: keep them together, but make sure not to mutate them
- question: where are dependencies defined?
  - NOTE: only containers need to define dependencies
  - question: how to define a node which is shared between multiple trees (eg. the same thing is processed in 2 places)
    - just because something is build like a tree, doesn't mean there can't be jumps in it
      - can have a "get_layer_with_name" node
  - conclusion:
    - parents automatically depend on their children
    - a "get_layer_with_name" node depends on that layer
    - more dependencies can be defined within nodes
- question: should we be able to add nodes in the graph after build-ing?
  - eg. add special intermediate nodes
  - use case: container node wants to create some sort of state that it's children can depend on
  - conclusion: no
    - one would have to make sure it's initialized just like in build
    - this kind of change seems like it would make it easy to violate assumptions / principle of least surprise
- how to do composite node dependencies properly
  - ie. how to pass input of sequential node to first node
  - how do you have it return the output of its last child? (sequential node)
    - the input of a composite node will be set by its parent - thus it can't set it's own dependencies on its children
  - how to express dependencies of first child:
    - first child depends on input of sequential node
    - last child depends on other children
    - sequential node output depends on last child
    - if first child depends on sequential node, this causes a cycle
  - there is a true dependency between the input of the sequential node and its first child
    - thus it makes sense to make this explicit
  - conclusion:
    - walk tree from top-level to bottom level, so that a dependency between the input of the sequential node and the first child can be set
  - alternative:
    - some form of graph unification
      - eg.
        - unify inputs of sequential node with inputs of first child
        - unify outputs of sequential node with outputs for last child
- question: how are inputs passed into a node?
  - parent node should handle it
- question: how should the input to a node be passed in?
  - options
    - function argument
      - pros
        - more expected
        - can enfore the right arity
      - cons
        - can't specify which key in the output map
    - through the graph
      - eg. self.graph.my_input(some_key="output")
    - through the graph w/ sugar
      - eg. self.get_input(some_key="output")
  - conclusion:
    - through the graph w/ sugar
    - no positional arguments (much harder to specify in a graph)
- why have wrapped variables?
  - additonal metadata
    - eg. shape, tags
  - custom rules
    - eg. related to tags
      - shared variables should be parameters and either weight / bias
      - weight / bias -> also parameter
    - eg. parameters must be shared
  - why make them lazy?
    - original motivation: to allow stage-wise initialization
      - eg.
        - first create the shareds
        - then perform operation with them
        - then adds some values in
  - pros of unwrapped variables
    - can directly look at the computation graph for dependencies
  - solution:
    - include a reference to the wrapped variable in the theano variable
      - so that the computation graph can still be walked for dependencies
- why not using tagging on theano variables?
  - because theano variables can be shared between networks
    - the state of one network shouldn't be messed with the state of another
- question: should nodes update themselves or should a higher level node do it?
  - pros if nodes updates themselves:
    - nodes can make sure each update only occurs once
  - pros of higher level node doing it:
    - code might be cleaner - because it can update all the weights in a single batch
  - question: is there any way to set higher level nodes to only update the weight of a unit once?
    - or can a lower level node override those updates
  - conclusion: higher level node can do it, lower level nodes can override
- how to compute update deltas?
  - compute bottom-up in architectural tree
    - pros:
      - can be done by adding immutable UpdateDeltas together
  - compute top-down in architectural tree
    - so children can overwrite / add
    - pros:
      - more complex logic can happen in a single mode
    - cons:
      - if using a single mutable UpdateDeltas, then inner nodes can see state of nodes that aren't its parents
        - eg.
          - b<-x->a (x w/ children a,b)
          - x computes its updates
          - a can see x's updates
          - thus a can also see updates for node b from x
          - whichever of a,b is computed second will see updates from the other
        - this may cause errors as well if one accidentaly updates weights that they shouldn't be able to see
  - add it all together
    - must be equivalent to an implicit top-down
      - eg. in order for a node to zero out updates to its children, some sort of top-down process must occur
    - pros
      - simpler interface
    - cons
      - complexity must be implemented anyway - why not expose it
  - conclusion: top-down
    - rationale:
      - lower in the tree is more specific, and you'd more likely want to perform an effect on a general setting than apply a more general effect to independent local settings
        - eg. if you want to zero out updates, more likely a non-local update than lots of independent local updates
- how should updatedeltas be updated (assuming top-down / root-to-leaf computation)?
  - it seems that either implicitly or explicitly, update deltas need to be passed into nodes
    - how else would a node zero out the updates?
      - doing so declaratively is a (complex) possibility
        - especially a simplified version with only the ability to add / overwrite
  - options
    - update_deltas should be passed in to a compute_update_deltas function
      - pros
        - consistent with normal python functions
    - update_deltas should be accessed as a attribute of the current node
      - pros
        - makes it clear where they are stored, always being in the same place
        - they should be accessed as an attribute in the future
  - conclusion:
    - update_deltas should be shared for a network
      - because
        - a single network should have a single set of updates
        - every node gets access to the updates anyway via compute_update_deltas
        - the updates should be stored somewhere
          - since they don't change, they can be cached
        - instead of storing then in some arbitrary node, we can store them in all nodes
    - update_deltas should be passed in to a compute_update_deltas function
      - rationale: simpler, makes sense, and might be useful for re-applying/re-ordering updates
      - note: should assert that compute_update_deltas returns None to make the interface clearly be one for mutation
    - because update deltas will be shared and mutable, their api should be made such that it isn't ease to accidentally mess than up
      - eg. use __iadd__ instead of __add__
- should computing output and update deltas happen at the same time?
  - no, because some node's updates will require outputs computed later in the DAG
    - eg. recurrent state would naturally have a loop
- the input arguments for computing the output of a node should be a function of the network
  - for nodes that dynamically get new input keys
    - eg. a node that is sent input
      - eg. a cost node that all costs are sent to
- node API
  - architecture nodes ONLY have 2 things: hyperparameters and children
    - in various desired formats
      - might want custom ways of inputting children
        - eg. networkx DAG
      - might want custom ways of inputting hyperparameters
        - eg. hyperparameter node
          - takes in kwargs
        - eg. something that provides stateful hyperparameters
    - how to effectively define these things in an easy to use way?
      - to minimize overall work + maximize simplicity
        - specifically in:
          - __init__
          - getting hyperparameters
          - getting children
          - serialization
    - how to define hyperparameters and children?
  - what is a node composed of?
    - state
      - name
      - hyperparameters
      - children
    - functionality
      - setting dependencies
      - initializing network state
  - which methods should be instance methods, which should be class methods?
    - architectural logic should be instance methods
      - stateless
      - could be shared between multiple networks
    - network logic should be class methods
      - by updating a shared network state
  - why should the node computations methods be class methods?
    - because it should not depend on the parameters of the node at all
      - hyperaparameters should be read from the network
      - inputs should be specified externally (input_keys)
  - should they be required to be classmethod's / staticmethod's?
    - pros
      - intention is clearer
    - cons
      - more complex interface for extension
    - conclusion
      - no - keep it simple and trust the user not to do something crazy
- where should state be stored?
  - all network state should be stored in a network specific object, not in the nodes
- why not just wrap blocks?
  - pros
    - it seems like there are a lot of parts of it
      - eg. recurrence, attentional, monitoring
  - cons
    - additional complexity
    - it comes with features that are tied togther that we wouldn't want tied together
    - it's recurrence appears to be rather limited
      - the recurrence needs to occur in the apply() method
      - can't use other blocks inside recurrence (?)
- serializing network state
  - do we want to serialize network state, and if so, how do we do it?
    - specifically, not the values of shared variables (which will be serializable for sure), but the values of everything else
    - we probably don't want to serialize theano variables
    - most, if not all, of the state should be recomputable through the architectural tree
    - because treeano is a function from hyperparameters to theano variables, we know that the only state to store is that of shared variables
      - thus
    - there will be other intermediates states (eg. the state of an initialization algorithm (eg. Andrew Saxe initialization)) but those are simply means to an end (where the end is theano variables), which should be already "done" by the time network.build() is done
  - conclusion:
    - serialization of the architecture and shared variable state should be sufficient
- there needs to be separate concepts for function outputs and actual outputs
  - function outputs
    - the output of compute_output
    - function from input variables to output variables representing the computation
    - variables in subsections of the computation graph
  - actual outputs
    - the value of the node with respect to real input in the network
    - variables in the computation graph
  - most of the time they can be the same, but they will be different in the case of output transformations
    - eg. scan / recurrent networks
      - function outputs will be functions for a single time step
      - actual outputs will be sequences over time
  - how to implement it?
    - keep an original_variables map
      - mapping from node_name -> output_name -> variable
      - for all the original outputs of a node
    - keep a current_variables map
      - mapping from node_name -> output_name -> variable
      - for mutated final outputs of a node
      - a scan/recurrent node can edit this map to contain the "actual outputs"
    - network has methods (something like below, not necessarily the exact same name):
      - add_variable
        - adds variable to both original_variables and current_variables
      - replace_variable
        - adds variable to only the final outputs
    - NOTE: names can change in the future
  - rationale for keeping the original variables:
    - these variables can be seen as a function from input to output of a unit
- adding to updates vs adding to cost
  - adding to updates is definitely necessary
    - because some state is just updated
      - eg. rolling mean/variance
  - adding to cost
    - pros
      - if you want to use the same learning algorithm (eg. Adam), it is more convenient
    - cons
      - might be confusing to have 2 ways to do this
    - how?
      - options
        - add to a global cost
        - don't automatically add to costs
          - thus need to manually add to costs
        - have the ability to query for cost of a subtree
        - send the cost into a node that accumulates it, with a default node name
          - eg.
            - Sequential([L2RegularizationNode(), SendTo(node_name="cost")])
            - SumNode(name="cost") # sums all inputs
- how should "cost" be treated?
  - options
    - as a specific node
      - pros
        - explitict
        - seems very flexible
      - cons
        - makes it difficult to combine costs together
          - eg. L2 loss
          - would have to each have each "extra" cost specify the main cost, or have the main cost specify each "extra cost"
            - neither option is all that great
    - as a network property / state
      - eg. there is a network state with a key (default="global_loss" or "loss" or "cost") that update nodes by default add to
      - pros
        - makes it easy to add losses together
      - cons
        - new question: when are values added to the cost?
          - during compute_output?
        - uses addition as an implicit function for composition - is this always desired?
    - as the output of a node, then using a SendToNode to send the values as input of a different node (ie. a SummedCostNode)
      - pros
        - allows performing post-processing of values
          - eg.
            - multiplying by a value
            - taking a square
            - making it a margin loss instead
            - composing multiple losses with a max instead of addition
      - cons
        - more verbose
  - conclusion
    - use output of a node, and a SendToNode
- question: how to create nodes from other nodes?
  - why this is a problem?
    - it exposes implementation details
    - creates complexity at deserialization time
      - when constructed, generated nodes are not present
      - when deserialized, they are
  - options
    - psuedo-nodes
      - nodes that are in the DAG, but not serialized
      - pros
        - very composable, works exactly the same as a normal node
      - cons
        - adds noise to visualizing the DAG
          - this might not be that big of a deal
        - seems a little inelegant
      - how to implement?
        - have a serialization_children() function
          - pros
            - makes it known that it is a special case
          - cons
            - need to add to children, then later remove from them instead of handling logic of pseudo children in one place
            - works only 1 level deep
              - ie. can't make a child of a child a pseudo-node
        - overwrite architectural_children() to add the nodes
          - and have NodeImpl use ._children instead of .children
          - pros
            - more elegant that serialization_children() function
          - cons
            - still only works 1 level deep
        - create PseudoNode wrapper around node which gets ignored by serialization
          - pros
            - explicit, since it provides additional metadata
            - most composable
              - solves the "1 level deep" problem
          - how?
            - create BaseNode class that NodeAPI inherits from
            - make PseudoNode inherit from BaseNode
            - overwrite getattr to just behave like the wrapped node
            - implement ignoring in graph
            - to instantiate, intercept __init__ call
    - save the original children, transform the children lazily
      - ie. have the new children added only on architecture_children()
      - you want the original input, thus the original input MUST be stored somewhere
        - is it a hyperparameter, children, or is the API insufficient?
          - it behaves nothing like other hyperparameters
            - because it's effect occurs before the graph is constructed
          - it behaves very similarly to children
      - question: should transformed input be cached?
        - pros
          - can be faster
          - should be fine, because the architecture_children should be a pure function of the node's parameters
        - cons
          - mutates the node
- ScanNode
  - for controlling theano.scan
  - how?
    - find all input sequences for node
      - inputs into graph
      - needs to go to ScanInputNode
    - find all outputs for node
      - outputs from graph
        - find_variables_in_subtree(["output"])
      - eg. the result of every node is an output
    - find all initial states for node
      - eg. ScanStateNode
    - find all non_sequences
    - performs scan for all intermediate output values
    - set the variables in the graph to have the appropriate output values (sequences)
- ScanStateNode
  - contains inital state, that may or may not be a learned parameter
  - sets value at time t to be its input at time t
  - 3 conceptual kinds
    - constant initial state
    - shared initial state
      - potentially learned
    - initial state from the network
      - NOTE: could consider the 2 other cases as special cases of this one, where the constant state or shared state is a special node
  - hyperparameters
    - where in the network to initialize state from
      - this is a hyperparameter because taking the initial state as the input to the node is almost certainly wrong in the context of a scan node (you want to initialize with a value that is not dependent on time)
    - how many time steps back to look
- what is the proper way of initializing long-range dependencies?
  - these behave differently from other dependencies and cannot occur in the normal order
    - eg. if a SendToNode sends its output to a SequentialNode that has already had its state/dependencies initialized, this messes up the dependencies of the latter's children
  - what order makes sense for init_state?
    - going top down makes sense
      - rationale: if a parent sets up dependencies for its children, children can then manipulate/introspect their dependencies
        - eg. SequentialNode currently uses this
  - options
    - special case SendToNode's in network.build to call it before all others
      - cons
        - inelegant
    - have an init_long_range_dependencies method for nodes
      - has no guarantees about which order these would be called in
      - pros
        - more general than special casing SendToNode
      - cons
        - adds more to the node interface
    - make init_state idempotent and calling it again
      - pros
        - it's generally nicer to have things idempotent
        - can ensure that init_state is called in an order that makes sense
      - cons
        - (unnecessarily?) limiting
        - some amount of upfront work
        - might be unsufficient
          - ie. might have to undo some effects - which will lead to it being limiting
    - make init_state not dependent on network topology
      - pros
        - simpler (?)
      - cons
        - very limiting
          - how to solve the sequential node input forwarding issue?
  - conclusion
    - going with init_long_range_dependencies
      - most general (ie. will allow other nodes to reimplement what SendToNode does) while solving the problem
- nice to have feature: auto-convert children nodes as strings to reference nodes
  - how to do this?
    - promote ReferenceNode into core/ (?)
    - where would this logic go?
    - the nodes would require a unique name
  - should we do this?
    - pros
      - would make the syntax a lot easier
    - cons
      - inelegent / requires special casing
      - results in a node without a name
    - conclusion
      - no need to add it to the core
      - we can later add an easier interface for representing networks of nodes
      - that way we can keep interface logic in one place
- what is the best way of handling nodes with multiple dependencies?
  - use cases:
    - cost node
      - takes in prediction and target
    - update node
      - takes in cost and parameter subtree
  - alternatives
    - take in an argument of the reference
      - pros
        - makes the most sense architecturally (?)
      - cons
        - somewhat repetitive
    - expect an input with a given to_key
      - cons
        - hardest to guarantee correctness of
        - least idiomatic
          - because to_key's are not normally used
        - little current functionality that allows easy linking to to_key
          - ie. only SendToNode
    - take in a child node
      - pros
        - seems to be the most composable way of handling it
        - provides a location for nodes
          - ie. doesn't require container nodes everywhere to hold the nodes
      - cons
        - adds additional nodes to the graph
        - encourages weird topologies
          - eg. taking in an argument of the reference doesn't encourage the ref to be part of the subtree
        - what about nodes that already have a child node?
    - take in a named child node
      - eg. SomeNode("foo", {"thing1": ANode(), "thing2": BNode()})
      - pros
        - would make more sense than taking in a child node
        - would enable other use cases as well
          - eg. split-combine node taking in split paths and a combiner node
      - cons
        - doesn't handle the case of nested children
          - eg. split-combine node taking in a list of children + a single combiner
  - conclusion
    - best option: taking in named child nodes
- named child nodes
  - problems
    - how to elegantly handle when most nodes only have homogeneous children?
      - in a way that fits with everything else
      - specifically, how does this behave when NodeAPI.architecture_children() is called?
    - how to handle nested data structures of children?
      - eg. a node that takes in one node, and then a list of nodes
        - eg. split-combine node taking in split paths and a combiner node
      - this is a problem for both:
        - a node reading in its children
        - converting the child container to data
  - solution:
    - typed schema
      - from string key to ChildContainer constructor which is performed recursively
- should parents be allowed to have children that the parent does not depend on?
  - rationale:
    - dependencies are relevant to ~compute_output~, not necessarily the other phases of network building
    - no matter what, parents have to have children that they don't actually depend on - the question is whether or not that should be reflected in the computation graph
      - eg. computing quantities only relevant to updates
  - use case:
    - should an update node store a cost node?
      - pros
        - it gives the cost node a spot in the subtree
      - cons
        - somewhat makes less sense from a computation graph perspective
  - conclusion:
    - yes, because the computation graph should reflect the logical network (in this case)
- how to handle batch axis in a modular manner?
  - how to handle initial state in recurrent nets in a modular manner?
    - needs to be repeated batch dimension times
  - also used in nodes like bias node and batch normalization
  - alternatives
    - hard code it in
      - ie. batch_axis = axis 0
      - pros
        - minimal boiler plate
        - batch size is used by many things (eg. which dimension bias nodes should broadcast over)
        - every other library does this
        - seems unlikely that we would frequently want to change which dim is the batch dimension
      - cons
        - additional assumption
        - counter-example: cuda-convnet uses c01b
    - have a default argument of batch_axis for nodes that need it
      - pros
        - makes a lot of sense with current design
      - cons
        - this logic will be peppered everywhere
        - lots of nodes will end up requiring batch_axis, when it seems like it could be an assumption that a batch_axis exists?
    - have some sort of global defaults container
      - pros
        - general solution
          - may be useful for other commonly used hyperparameters
            - batch_axis
            - channel_axis
            - scan_axis
          - it may be nice to have all this logic in 1 spot
      - cons
        - additional concept to build
  - conclusion
    - create simple global defaults map in network object
    - there doesn't seem to be enough use cases to justify a big global defaults container and an additional concept
    - by encapsulating this in network, it should be easy to change later
    - accessing values can still come from find_hyperparameter
- RNN initial hidden state
  - problem
    - the input shape must be the same as the output shape
    - the output shape may depend on the input shape (ie. identity)
      - thus cannot rely on looking at the output shape
    - the shape may not be available
      - eg. for zero initialization, or initializing with a shared variable
    - shape must be known ahead of time!
    - for parameters that are shared across a dimension, we need to know the eventual size of that dimension
      - thus needs batch size, etc.
  - solution
    - tile node - behaves like theano.tensor.tile
    - need to manually give the batch size
      - ie. can't be determined automatically
- have hyperparameter precedence favor closer to the node over more specific hyperparameter name
  - eg. if conv layer defines strides, but hyperparamnode defines conv_strides, use conv's hyperparameter
- initializations as a hyperparameter
  - problems:
    - should every unit with weights have the exact same set of hyperparameters? (shared_initializations, initializations, inits)
      - solution: yes for "inits"
        - that way units can have custom hyperparameters too
    - how do we specify precedence? (eg. preallocated initializations first)
      - options:
        - pre_inits hyperparameter which is applied first
          - pros
            - general, can apply to any kind of init
          - cons
            - need same logic everywhere
        - have logic for favoring PreallocatedInit's
          - cons
            - less elegant
        - create network-wide hyperparameter overrides with highest priority
          - pros
            - might be useful for other hyperparameters
          - cons
            - how do we do this right?
              - already have similar logic for default_hyperparameters
      - solution:
        - network-wide overrides
    - how to create hyperparameters with fallbacks?
      - eg. inits is a weight initialization, but up the tree there is a bias initialization
      - solution: create find_hyperparameters to generalize find_hyperparameter and flatten all together
    - should it be treated like any other hyperparameter?
      - pros:
        - allows custom initializations
          - eg. bias_inits, weight_inits, conv_inits
      - cons
        - complexity is pushed to every unit that has weights (eg. hyperparameters)
      - conclusion:
        - yes
          - very little downside, nice upside
- should we wrap lasagne's convolutions or make our own?
  - make our own pros
    - easier to extend
  - wrap lasagne
    - they're really good
      - probably won't change anything
    - not hard to switch over in the future
    - less code = better
  - conclusion:
    - wrap lasagne in the short-term
    - eventually make out own
- how can nodes pass hyperparameters into their children the right way?
  - ideally we want to apply it only to the correct children
  - use cases
    - sometimes parents pass a hyperparameter to a child with a different name
  - alternatives
    - override get_hyperparameter
      - pros
        - already implemented / needed
      - cons
        - ugly code
        - can't specify a hyperparameter for a specific child
    - allow get_hyperparameter to know which node is calling find_hyperparameter
      - in general, it seems like a good thing to allow more complex queries
        - eg. maybe when calling weight initializations, you might want to query based on type of unit
          - eg. to initialize recurrent states to something near identity
    - use set_hyperparameter for custom hyperparameters
      - in init_state
      - have ability to specify hyperparameter for a particular child
      - pros
        - can specify hyperparameters for exactly the child you want
      - cons
        - hyperparameters can't be set lazily
        - need to set state in init_state
          - this has issues
            - this occurs after init_long_range_dependencies, and some hyperparameters are needed for that
              - solution: for those nodes, call set_hyperparameter in init_long_range_dependencies
    - pass partial created network into architecture_children
      - rationale:
        - can query hyperparameters and pass them to children
      - it might work, since architecture children is called from up the tree to down it, thus all parents of a node should already be in the network
      - pros
        - uses existing abstractions
      - cons
        - hyperparameters can't be set lazily
        - can't be done currently
          - architecture children is currently being called before the architectural tree is even created
            - it's also called multiple times, which may cause issues
  - conclusion:
    - set_hyperparameter function
- should DictChildrenContainerSchema have optional values
  - use case:
    - identity node for costs
      - costs can both be passed in explicitly or sequentially
    - auxiliary cost nodes can have additional hidden layers
  - if all keys are optional, can None be passed in instead?
    - would allow lots of nodes to have default parameters
  - can a single node be passed in if the node takes in a single child?
  - should it be explicit (some optional=True flag) or implicit (error out when trying to get key)?
  - pros
    - API win
  - cons
    - less verifiable
  - conclusion:
    - yes! allows much less repetitive code - since the same logic can be more polymorphic
- should shared variables always require "inits"
  - why?
    - to resume state
    - to share between networks
  - is there a way to make this less redundant?
  - I've been bitten by this bug multiple times
  - conclusion:
    - yes! better to prevent these kinds of bugs
- how do we add weighted costs?
  - alternatives
    - special node with weights
      - cons
        - not entirely decomplected
          - this would have to go into the total cost node (or something like it) anyway
    - optional argument to total cost node
      - cons
        - no reason to add it here it it could otherwise be added to aggregator or elementwise cost
    - optional argument to aggregator node
      - cons
        - the weights are somewhat specific to costs, while the aggregator doesn't have to be cost specific (they just aggregate to scalars)
    - optional argument to elementwise cost node
      - pros
        - implementation is easier
          - beause arguments of total cost node are just passed into this
  - conclusion
    - optional argument to elementwise cost node
* canopy - general
- treeano should not have hooks
  - there should be a clean separation of mapping from parameterization to theano variable and all the extra (modular) logic
- canopy
  - layer on top of treeano
  - handles non-theano modularity
  - nice reference
    - the only layer above this is the emergent layer (your code)
- training loop
  - what interface?
    - needs
      - data
      - training function
      - after training handler
        - this could be combined into the training function
    - simply:
      - for thing in gen: fn(thing)
      - fn can be wrapped by arbitrary handlers
  - handler state should be hierarchical
    - eg. wrappers = [stop_after(seconds=100), handle_every(5, some_other_wrapper), ...]
      - here some_other_wrapper needs state under handle_every
    - so that inner state can be serialized
  - training_loop_from_network
- handled function
  - should it take in a built network or the raw nodes?
    - pros of built network
      - can pass in initialized state as well
    - pros of raw nodes
      - more time efficient
        - eg. don't need to calculate derivatives
    - conclusion: take in a network that may or may not be built
      - to get the benefits of both
  - it should take in an inner_handler, and be built up recursively
    - that way it can serialize it's internal state and load it up
  - would one want 2 functions from the same network?
    - no, this is a handled function
- handlers
  - each handler needs:
    - to be able to add/access it's own state
    - add/access all state of children
    - take in an network
      - and possibly change it
    - take in the arguments for a function
      - and possibly change it
      - eg. mode
- should handled functions always take in and output a dict?
  - should the input be kwargs instead?
    - pros
      - simpler syntax
      - easy to convert input dict to kwargs (eg. **indict)
    - cons
      - can't have additional kwargs
        - will theano functions ever need this? possibly not
        - handlers might use kwargs
      - requires string keys
      - using kwargs involves making lots of copies
        - probably doesn't matter
    - can just have kwargs_to_dict or dict_to_kwargs handler
  - pros for dict input/output
    - makes it easier to output additional fields
      - eg. monitoring
    - makes it easier to have handlers that depend on the output of other handlers
      - eg. AUC handler that takes validation handler into account
    - easier to take in maps as input
    - allows for default keys for certain things
      - eg. "output", "loss"
  - cons
    - more boilerplate for the simple case
    - will break existing handlers that do any sort of input/output manipulation
    - introduces issues of colliding kwargs
    - may be harder to debug when something goes wrong with theano.function
  - conclusion:
    - really need to pick one a stick to it
      - to allow for input/output manipulation composability
    - output should be a dict
      - because it enables many complex use cases
        - eg. monitoring by adding to the dict
    - input should be a dict
- attaching handlers to networks instead of functions
  - rationale:
    - composing together function handlers
      - eg. some assigned in training loop, some assigned outside
    - sharing handler state
      - eg. shared variable for chunking
    - serializing networks with preprpocessing
  - make handled network class
    - override .function
      - call handled_function
    - add .wrap_handlers
      - returns new network
    - add .wrap_handler
    - add .get_handlers
      - to get all handlers out
    - get .get_base_network
      - return the original network
  - issue:
    - sharing handlers shares state
    - some handlers have function specific logic
      - eg. which keys go where in chunk_variables
  - conclusion:
    - should keep handlers simple and not do this
    - if handlers should share state, the same handler can be used for multiple functions
- how to properly handle monitoring?
  - how to do learning curves?
    - callback every iteration
      - this way it behaves like live plotting
  - how to handle monitoring?
    - what controls monitoring?
      - alternatives:
        1. simple handler, nodes control monitoring
           - nodes have flags to create monitor variables
           - handler queries graph for all monitor variables
             - does something with them
               - eg.
                 - prints them
                 - makes a plot
           - pros
             - same interface / implementation to parameterize node as to control monitoring
        2. simple nodes, handler controls monitoring
           - handler is either given a node or a query (eg. all dense nodes) for variables to monitor
        3. some combination of both?
      - conclusion: nodes control monitoring
    - should there be a common switch for all nodes to enable/disable monitoring
      - alternatives
        - no switch
          - cons
            - lack of consistent interface to disable monitoring
            - can't disable monitoring for a heterogeneous subtree
        - as part of framework
          - pros
            - hardest to screw up
          - cons
            - additional assumptions in framework
        - by convention
          - pros
            - gets benefit of having switch without having to build it into framework
          - cons
            - less DRY since logic needs to be everywhere
      - pros
        - consistency
    - how do you monitor scalars?
      - should we add an assertion for monitor variables to have shape ()
      - printing?
      - plotting over time?
        - w/ matplotlib
        - w/ text gnuplot
      - need to add it to theano function outputs
        - to perform GPU transfer efficiently
        - thus need a handler
          - how much complexity in the handler?
      - can costs be a monitored variable as well?
    - how do you monitor tensors?
      - might want to make a gif of an image?
      - otherwise might instead just summarize to a scalar
      - this might warrant it's own handler to save a bunch of tensors to a directory
    - how do you combine train and valid monitoring?
      - possible solution:
        - have monitoring handler take in a prefix / format string
        - all monitor names are formatted according to that string
    - how do you create variables for updates and not compute them when not updating?
      - ie. how do you make sure update-specific monitoring variables aren't unnecessarily computed
      - alternatives:
        - some smart built-in thing
          - eg. a variable wrapper tag
          - automatically determines which monitored variables should be used
        - ignoring the problem
          - eg. you might want update statistics on valid set even if the update isn't performed
        - a manual flag
          - this would allow one to choose the right behaviour
* assumptions
- shared variables (eg. parameter tensors) will have a fixed size
- nodes are in a directed acyclic graph
  - thus can be traversed in a topological sort
- initialization schemes can work in a topologically sorted order
  - eg. not from output to input
  - not necessarily true, but a simplifying assumption
- shared variables are either a "parameter" (ie. backproped to optimize) or "state" (ie. not backproped)
- shared variables (eg. parameter tensors) are owned by a single node in the computation graph, and that node is responsible for their updates
- node names are strings
- all nodes will have a default output
- shape dimensions of None mean that the shape is unspecified
- a batch_axis is None, then there is no minibatch (doing single element at a time)
- shapes should be tuples
- batch axis is the same throughout the network
* misc
** Should I use this?
- Do you not know what a neural network is? Use [[http://scikit-learn.org/stable/][scikit-learn]].
- Do you want to use only the tried and tested elements of deep learning? Use [[http://caffe.berkeleyvision.org/][Caffe]].
- Do you want to create novel architectures? Use [[https://github.com/Lasagne/Lasagne][Lasagne]].
- Do you want to create novel architectures that are inelegant to do in Lasagne? Use [[https://github.com/Lasagne/Lasagne][Lasagne]].
- Have you created these novel architectures that are inelegent to do in Lasagne? If you can live with it, keep using [[https://github.com/Lasagne/Lasagne][Lasagne]].
- Are they inelegent because they are recurrent? Try [[https://github.com/mila-udem/blocks][blocks]].
- Still not satisfied? Maybe this is a good fit. (:
** What's with the name?
- DAGano doesn't have the same ring to it
- architectures are constructed as immutable trees, and this allows you to customize the behavior of subtrees instead of manipulating a single global network
  - principle of locality: it's more likely that you'll want close-by nodes to behave similarly - thus having subnetworks makes sense
  - immutability is a good means of managing complexity - thus a tree makes sense
** random notes
- model everything as a "layer"
  - including loss/objective
  - maybe even represent gradient descent updater as layer node
    - takes in trees of things to update, and loss, and generates updates
  - layer : higher level unit than theano node
    - high level enough that it deserves to both be know and named
  - compose base layers together with functions
    - make sure that functions add a named identity layer
  - use paths instead of strings as names
- issue: how to update an existing architecture to eg. use dropout
  - have a top level assoc_in
    - to add new parameters or replace layers
- responsibilities of each "layer"
  - serialization
  - deserialization
  - output(s)
    - default key for output: "output"
    - map w/ names
    - rationale for multiple outputs:
      - monitoring is one possible use case
  - shape(s)
    - optional: can auto-compute
  - update(s)
    - optional
  - dimension(s)
    - maybe?
- everything has names and paths
  - each node needs a name
  - names are like relative paths
  - paths are absolute in the network
    - tuples of names / indexes
- sharing shared: separate step for initializing shared
  - pass in a map from path to shared, which can be used instead of creating a new shared variable
- sharing weights: separate step for initializing weights
  - pass in a map from path to weights, which can be used instead of creating a new shared variable
- sharing params:
  - use a network.assoc_in(path, value)
    - eg. top_level_network.assoc_in(["deterministic"], True)
- question: when are shareds / weights initialized
  - initializing shared
    - prereq: dimensionality, broadcast dims
  - initializing weights
    - prereq: shape
- state in a node is divide into:
  - hyperparameters
  - shared variables
  - intermediates
- how to do shared initialization:
  - kinds of shared initialization
    - exact path initialization
      - eg. ("FCs", "head", 1, "FC")
    - partial path initialization
      - eg. ("some_initalization", "something", "my_cool_layer", "FC") equivalent to ("my_cool_layer", "FC")
  - question: conceptually, how does one perform initialization with existing shareds
    - SharedInitialization.fromNode(other_network, backup_initialization=NoInitialization())
      - set default to having no init
* about
** features
- GOAL: it should be easier to do NEW things than theano
- modularity
  - kind of a design goal of the other features
  - "tricks" can be made 100% self-contained
- composability
  - storing updates as changes in the values instead of new values
    - allow arithmetic on the amount changes
  - nodes can update themselves
- hierarichical specification of hyperparameters
  - customize each subnetwork
- serialization
  - including
    - architecture
    - parameters
    - all other state
      - a necessity for doing things like restarting training with stateful optimization algorithms
** planned features
- easy variable sharing between networks
- easy weight sharing between networks
- auto-"chunk"-ing theano variables
- automatically computing shape of node outputs
- graph transformations
  - eg. give me a new network with all ReLUs substituted for leaky ReLUs
- recurrent networks
** hard to do in other packages
- serialization
- freezing the parameters of some part of the network
- increasing learning rate / step size for some part of the network
- applying transformations to updates (eg. gradient clipping)
* TODOs
** decisions to make
- hyperparameters that affect initialization
  - eg. reading in in_axes and out_axes from the network
- hyperparameters that affect topology
  - eg.
    - whether or not to send input to children
  - should it even be an option?
  - some way of having static "hyperparameters"?
    - eg. ones that affect the architecture
    - example: make this same unit 3 times
      - eg.
        - conv-conv-conv-pool
    - maybe this should be a function
      - doesn't have to be a concept built into treeano
- should shared variables contain metadata on which axes are their input axes and which are their output axes
  - useful for initialization
** annoyances
- writing recurrent nets using scannode is much worse than writing in theano
- having an explicit batch dimension seems to cause quit a bit of complexity
- hyperparameternode's seem unnecessary
  - maybe we should be able to add hyperparameters anywhere in the tree
- having everything with "Node" at the end is unneccessary
- all nodes with shared state need to make sure that they get inits from the network
  - also requires the same concat line every time
    #+BEGIN_SRC python
      inits = list(toolz.concat(network.find_hyperparameters(
          ["inits"],
          [])))
    #+END_SRC
- the children container abstraction is ugly and unnecessary
  - how would we do this in clojure?
    - create children as data
    - explicitly add additional data that shows how to read that data
    - same thing w/ names + hyperparameters
    - remove nodeapi/nodeimpl distinction
** big changes
- maybe: nodes should provide depdendencies for traversal
  - eg. "I need my parents' compute_output for my architecture_children"
  - so traversals can be in alternate orders
    - issue: what if generated children have init_long_range_dependencies
- ability to search for arbitrary things
  - eg. updates
- maybe: hyperparameters when constructing tree
  - so that batch norm node can control which of those children nodes should be created
  - removing the bias from FC/conv layers with batch norm
    - since it doesn't do anything with batch norm
- maybe: remove polymorphism over batch axis, etc.
** v2
- parameterize weight matrices
  - use cases:
    - weight sharing (transpose)
    - making weights a function of the input
    - drop connect
    - bayes by backprop
  - issue:
    - how to specify shape / initialization if weights are external
  - could maybe have a "WeightNode"
    - it could have input axes and output axes
      - for both monitoring and initalization
  - need to separate computation of initial state of a weight from using the weight
    - eg.
      - separate weight usage into 2 parts
        - preparing metadata for the weight
          - shape, dtype
        - using weight
          - actual logic
  - what if nodes could create children during compute_output?
    - the shape/dtype could be passed in as a hyperparameter
    - issue:
      - children cannot init_long_range_dependencies to a done node
      - children cannot init_state and change dependencies to a done node
- nodes should have a setter for name
  - if can't be abstract, should have an assertion error
  - make sure ._name (or whatever it is) is not accessed
- if variables are needed before init_state, then variablehyperparameternode might break
- consistent shared variabling name bias/b, weight/W
- should there be utility functions for getting common hyperparameters?
  - use cases:
    - deterministic
    - monitor
  - pros
    - more DRY
    - less error prone
      - eg. might misspell something
    - having optional conventions is almost practically the same thing as requiring it, since everyone will use it
      - the main difference is that these abstractions can be implemented without changing the core of the library, which is nice
  - cons
    - more "magic"
    - causes heterogeneous code
      - quite often one will want to not use it (when they want the normal find_hyperparameter order to work)
        - if network.find_hyperparameter(["deterministic", "enable_dropout"])
- remove dependencies for nodes whose children are only for updates
  - MAKE sure to document this and why it occurs, and why having dependencies for computing updates would be bad
    - ie. mutate_update_deltas should not have dependencies between nodes
  - use case:
    - want to optimize a subtree of a network, but the cost is elsewhere
      - cost cannot be a dependency of the update node, since the cost is computed after its output
- graph containers
  - containers.GraphNode
    - takes in networkx graph
      - need metadata of which nodes to send input to
      - need metadata of which nodes to take output from
  - containers.EdgeListNode
    - can be very useful for defining recurrent architectures
    - given:
      - unordered list of nodes
      - edges
        - mostly pairs
        - must have way of including to_key and from_key
        - incoming edges from nodes not in graph are reference nodes
        - outgoing edges from nodes not in graph are send to nodes
- util for getting inits from network
- use joblib for serialization
  - rationale: much more efficient for numpy arrays
- multistage training
  - eg.
    - unsupervised training
    - training the classification layer
    - fine tuning the whole thing
- compare caffe inception time to theano inception time
- setup continous integration
- make find_inits(additional_hyperparameter_names, default_inits) utility function
- make node for each cost + auxiliary versions of cost + auxiliary version w/ dense node
  - rationale: can have cost-specific monitoring
    - eg. for hinge loss, the % of beyond-margin points
  - CategoricalCrossEntropyNode
    - CCENode
  - BinaryCrossEntropyNode
    - BCENode
  - SoftmaxCCENode
  - TemperatureSoftmaxCCENode
  - AuxiliaryDenseSoftmaxCCENode
- need evaluate_until to store state
  - losses, times, total_time, etc.
- misc canopy
  - creating training curves
  - saving models every x iterations
  - saving first / best / last model
- ability to merge output of multiple calls
  - take functionality from chunk_variables
  - use case:
    - merging results of multiple training/validation chunks
- remove print statements
- should "weight" inits be linear weight inits
- issue: serialization of handlers
  - what if handlers have theano variables as state? that may break when serializing
    - solution: need to implement getstate/setstate
  - how to properly deserialize handlers for handled networks
    - ie.
      - handlers are normally shared across multiple locations
        - eg. multiple handled networks, multiple handled functions
      - except when serializing/deserializing
- upsample.BilinearInterpolationNode
** canopy.handlers
- don't use __call__ for handlers
  - some kinds of handlers don't need state
  - for more modularity, we should separate out the kinds of handlers:
    - eg.
      - pre-call handlers
        - manipulating input
      - post-call handlers
        - manipulating output
        - eg.
          - saving monitoring data
      - no-network-state pre+post
        - eg.
          - timing
  - then the other handlers can overwrite __call__ in the most appropriate way
    - eg.
      - pre-call handlers are just functions on input kwargs
      - post-call handlers are just functions on result
      - no-network-state pre+post can be a context manager
        - eg. ~with time_call(...)~ or as a handler
- canopy.handlers.conditional.handle_every
  - instead of taking a function, takes in a handler, and only sometimes does the __call__ method of the handler
  - add TODO to take in a list of handlers instead of a single handler
- build
  - run in different process (w/ different GPU)
    - https://groups.google.com/forum/#!msg/theano-users/niQ8j_TNoqM/Y5_1ETIc3WUJ
    - use below to manually set gpu (before that, shared variables are created in the CPU):
      import theano.sandbox.cuda
      theano.sandbox.cuda.use(theano.config.device)
  - convert args to fX handler
  - stopping conditions
    - time
    - # iterations
  - passing extra input to the network (curriculum learning)
  - saving model
  - validation
    - assert shape of numpy array is same as that of the input variable
  - pre/post processing input/output
  - compile with nan detection mode
    - NOTE: we already have code for a nan detection mode, but having this as a template would probably be useful
    - http://deeplearning.net/software/theano/tutorial/debug_faq.html
      - search for detect_nan
      - filter out str(node).startswith("GpuAllocEmpty(")
      - try to see if output[0] can be called as arg to np.isnan
        - cannot convert PyCObject
  - chunking
    - add flag for caching
      - cache=None or "hash" or "id"
        - hash caches on numpy array hash
        - id caches on exact array
      - optimization to make datasets that fit in memory fast
    - flag for random order of minibatches
    - time transferring data to shared variable
    - add flag to not free memory afterwards
** RNNs
- https://github.com/Lasagne/Lasagne/issues/425
- https://github.com/craffel/nntools/blob/recurrent/examples/recurrent.py
  - see:
    - how a mask is used
    - the generated dataset
- lasagne "Add recurrent layers" pull request
  - https://github.com/Lasagne/Lasagne/pull/294/files
- use batch_axis instead of batch_size
  - use symbolic shape to tile if batch size is None
- some nodes will be broken with ScanNode
  - ie. batch normalization updates
- create transform to apply non-stateful nodes like in scan, but instead use batch dim
  - eg. to apply dense to a sequence, reshape it so that batch + time are folded together
- test if nested scans works
  - eg. if can theano.clone
- goals: have recurrent net working as fast as if done in pure theano w/ strict=True
- time whether having lots of little scans or 1 big scan is better
- test if computing extra outputs slows scan down, even if they aren't used
- ScanNode recurrent architectures (LSTM/GRU)
- add in normal (non-scannode) LSTM/GRU/SRN
- fix FIXME's in scan.py
  - more sophisticated way of finding nodes in subtree
    - eg. finding scan state nodes whose scan is the current scan
- RNN note: mask for padding
- add truncate_gradient parameter
- taps for recurrent nets
- how to handle updates for RandomStates?
  - options:
    - ignore it and have default_updates handle it
      - it would have to be explicitly ignored by scan
    - add it to the updates
      - problem: what if there are multiple scans - adding the updates don't make sense in this case
      - pros:
        - easier
- theano.scan(strict=True)
  - problem: issue with passing in random variables
    - options
      - ignore and use strict=False
      - have a flag to ensure strict=True
        - somehow verify that the graph has no random variables
  - how to find non_sequences
    - if a node accesses state from somewhere else in the tree (not under the current scan node), treat that output as a non-sequence
    - treat RNG as a non-sequence
    - all shared parameters in the current subtree should be non_sequences (?)
    - maybe have a tag "non_sequences" for variables in the current subtree to be treated as such
      - everything else is treated as an output?
  - how to deal with non_sequences
    - remember which variables are non-sequences and use theano.clone to do a variable replace with the new variables representing the non-sequences
- how to deal with multiple sequences to recur over?
  - eg. sensor setting
    - sequences: some visual signal, some numeric signal
  - alternatives
    - have scaninputnode take in all inputs of scannode and forward them along
      - then need reference node to read in the proper output variable from the scan input node
      - pros
        - semantically correct
      - cons
        - need the scaninputnode's name
          - solution: name can be looked up like a hyperparameter
    - have RecurrentInputNode's be manually specified, along with the key to be passed in
      - looks at the input of the scan node with the key, and creates an input variable of the proper shape
      - pros
        - simpler than previous
      - cons
        - the "normal" case of a single input is harder
        - creates more "noise" in the graph
    - have a ScanAwareReferenceNode
      - the node is aware of scan's semantics and performs the appropriate transformation of the variable
      - this reference node can reference variables outside the scan, and the input gets automatically converted to an element from a sequence
      - pros
        - simplest of all
        - most similar to non-scan functionality (referencenode)
        - can add afterwards, thus allowing implementing the default case first
      - cons
        - doesn't work for nested scans (how do you know how much un-sequencing look like)
          - solution: make it explicit about how many scan levels up/down to convert a variable
    - make sequences / forwarding be a parameter of ScanNode (takes in a map of nodes and which outputs to forward to)
  - conclusion:
    - for now, use the ScanAwareReferenceNode seems like the best solution
    - because it is compatible with the single output design, we can do this later
- implement
  - LSTM / GRU
    - https://github.com/fchollet/keras/blob/master/keras/layers/recurrent.py
    - https://github.com/mila-udem/blocks/blob/master/blocks/bricks/recurrent.py
** shape calculation
- try test_value's with scan
- maybe have shape be a symbolic scalar - that way equality checks can be done
  - eg.
    - let x be variable batch size
    - let y be variable time size
    - can have some nodes have shape 3 * x
  - can make them theano variables, and have a completely separate theano graph for batch sizes
- figure out how to make recurrent node's not require batch size
  - would be cool to have symbolic shapes work
- auto shape computation
  - use FAST_COMPILE mode, and do .shape symbolically, in case it can be optimized
  - can use compute_test_value for shape computation
  - eg. T.zeros((3,4,5)).shape.tag.test_value
** misc
- TheanoExpressionNode()
  - input:
    - output
      - as a variable
      - or dict from name to variables
    - input (from the graph)
      - as a variable
      - maybe a dict from to_key to variables
  - pre-requisites:
    - auto-shape calculation, to make it easy
- ipython notebook template with common actions
  - eg.
    - visualization
      - error analysis
- simpler way of reshaping
  - eg. I want to divide this dim by 2 and multiply this dim by 2
- add way to filter parameters and only apply updates to a subset
  - use cases:
    - nesterov momentum
    - l2 weight decay
    - any update node
  - one might argue that one could choose which nodes to wrap, but some nodes might have multiple parameters
- percentile tests fail for floatX=float64
- generalize / share code between stochastic:
  - dropout
  - spatial dropout
  - gaussian dropout
  - variational dropout (adaptive gaussian)
- parameterize spatial axes (similar to batch_axis)
- consider a switch shared variable to determine whether or not to use dropout
  - so that network doesn't have to be recompiled
  - should there be some easy way of toggling these kinds of variables
  - need to recompile anyway, since network at validation time won't have updates
- figure out how to handle random state
  - should rng state be global, part of the network, state of a node?
    - should not be global
      - this is a memory leak since the srng object saves the state_updates
    - NOTE: be careful with monitoring, since the rng state is just some random bytes
  - where to put the serialized state?
    - problems:
      - shared variables are not named
        - can name them
        - ie. wrapper function: network.rng.binomial(name="blah", ...)
- more information when querying
  - will allow for more advanced filtering in the future
  - eg.
    - weight initialization
    - getting hyperparameter
- new parameter tags:
  - updates_state
    - rationale: might want to reset it
    - internal state of update algorithms
    - eg. learning rate, momentum, etc.
- updates composability
  - can compose together: momentum, nesterov momentum, etc.
- SubnetworkNode
  - take in an existing treeano model, but treat it like a black box, only using replace's on it
  - sample use case: dropout distillation
  - might be useful to configure certain things to pass through
    - eg.
      - hyperparameters queries
      - updates
- make sure all state of updates is stored in node
  - that way learning is 100% serializable
- ability to serialize only a subtree
  - that way training state (eg. updates) doesn't have to be serialized
- add testing files in examples/ to test cases
- have children container verify every element is of type NodeAPI
- rename UpdateScaleNode to MultiplyUpdatesNode
- rename ChildrenContainer.children
  - rationale: calling self._children.children looks like it's reading grandchildren
  - maybe self._children should be renamed
- make sure all register strings, node names, and to/from keys are in [a-zA-z_]
  - rationale: allows special symbols when creating nodes
    - eg. "dense#dense1"
  - maybe?
- allow theano var for inputnode to be a parameter to be passed in
- add check in compute_output phase to make sure network doesn't return additional inputs
  - rationale: they do not get recorded in the node's "inputs"
    - thus makes it harder to compute shape
- add shortcuts for nodes that wrap other nodes
  - eg. to inherit their hyperparameters
- think about how to specify if a node owns a weight
  - perhaps if nodes that used parameters had ParameterNode's, it would be easy to have a drop in replacement as a reference to a parameter elsewhere in the network
- change terminology to not refer to variable wrappers as variables
- relativenetwork
  - add __repr__
- cache gradient computation
- use assertions for outputs that should not be used
- test:
  - find_variables
  - preallocatedinitialization
  - theano.tag.test_value
    - http://deeplearning.net/software/theano/tutorial/debug_faq.html
- real initialization nodes
  - using a stateful class and a hyperparameternode is very wrong
    - just a hack
  - want to represent the parameters of the initialization as hyperparameters and have them be clone-able/inspect-able
- redesign from_key, to_key graph
  - rationale:
    - the edge is currently stores as something like (from_name, to_name, {from_key: xxx, to_key: xxx})
    - this means that only one connection from from_name to to_name can exist
- create more types of containers:
  - https://github.com/torch/nn/blob/master/doc/table.md
- tree of hyperparameter precedence
  - instead of having each node define the fallbacks of each hyperparameter, have it reference a tree so that shared hyperparameters have the same fallbacks
  - pros
    - consistency for users
  - cons
    - might be complex to understand
    - defining hyperparameters in more than one place
- lazy way of storing new values instead of update deltas
  - ie. if you have new_value, no need to store new_value - old_value to only add old_value back in
  - pros
    - saves a few nodes in graph
- grep for FIXME's
** debugging
- name all theano variables
  - https://groups.google.com/forum/#!msg/theano-users/QoXZZxP5uHE/Krptqwktp7sJ
    - options
      - g2 = theano.compile.deep_copy_op(g)
      - g3 = theano.compile.view_op(g)
        - doesn't support Rop
      - g4 = T.tensor_copy(g)
    - TODO benchmark
  - ie. add names to variables
    - var.name = "somename"
    - have a defined name separator
      - eg. $NODE:$VAR
    - TODO: also have a defined child name separator
      - eg. dense_bias, dense_linear
- save previous n layer outputs using shared variables
  - eg. https://github.com/tariqdaouda/Mariana/blob/master/Mariana/layers.py
- make sure all intermediate variables are named
  - for ease of debugging
- ability to instrument debugging in only a subtree
- auto-creating tag.test_value
  - http://deeplearning.net/software/theano/tutorial/debug_faq.html#using-test-values
  - NOTE: incompatible with scan
- auto return theano.printing.Print on VariableWrapper.variable in a debug mode
- store last x values of a variable
- look into auto-instrumenting local variables
  - see https://github.com/shawntan/theano_toolkit/blob/master/parameters.py for a way to get access to local variables in a previous frame
** guides / demos / concrete things to build
- try building:
  - triplet network
  - network with parameter sharing
    - eg. autoencoder with transpose as weight
- spatialdropout
- temperaturesoftmaxnode
- temperature softmax + categorical cross entropy + rescaling due to temperature (* T^2)
- gradient caching node
  - allows calculating derivatives of parameters with respect to loss high up in the tree (optimization)
- learning rate decay node
  - represents learning rate parameter as theano var w/ updates
- demos
  - fully connected layer mnist with num_hidden, activation specified once
  - separate conv layers from FC layers
    - different dropout and L2 for conv
- how to do things guide: (thinking in treeano guide)
  - freezing a section
    - use UpdateScaleNode, scale to 0
** network as data
- create DSL on top of nodes to apply transformations
  - insert_above(), insert_between()
- to_sequentials
  - take in nested lists like hiccup and convert into sequential nodes
    ["a", ["b", node1, node2, ["c", node3]], ["d", ["e", node5]]]
  - maybe have it be very hiccup like:
    ["a", {"num_units": 32},
     ["b",
      ("conv1", "conv", {"num_filters": 42}),
      ("pool1", "pool", {"strides": (3, 3)})],
     ["c",
      ("fc1", "fc"),
      ("fc2", "fc")],
     ("final_fc", "fc", {"num_units": 10}),
     ("output", "softmax")]
- add node metadata
  - eg. "update" "cost" "output" "hyperparameter"
  - this will allow for easier filtering when doing architecture transformations
    - eg. remove update nodes in this subtree
    - can use jQuery like syntax
      - something("node_name", {"type": "update"}).replace(lambda x: ...)
- create TransformationNode
  - applies transformations lazily
    - ie. not immediately but only when the network asks for its children
  - pros
    - lazy
      - work is done as late as possible
    - declarative
      - you show how to get the complex result, not the complex result on its own
      - readable
  - ie. AddDropoutBeforeDenseNode
** code quality
- consistent naming of VariableWrapper as vw
  - rename variable in network.py to vw
    - eg. find_variables_in_subtree to find_vws_in_subtree
- test serializing and recovering inner handlers
- create function to test initialization strategies (just that they do not break)
- PYTHONPATH=~/repos/treeano:$PYTHONPATH sniffer
- potential issue: sharing variables between networks when test_value's are enabled
  - if one network uses the same variables, but with different shapes, the test_value's might break
- auto-test nodes
  - have fast tests:
    - test serialization
    - test that it can get output from input
    - test that shape calculation is correct
  - slow tests:
    - for parameter layers:
      - test that loss can decrease: input -> node -> mean layer -> output
- testing
  - add serialization tests for all nodes
  - testing for cuDNN nodes
- copy downhill.test.util tests for optimizers
** other libs / snippets of code that may be useful
- nodes for data augmentation
  - eg. https://groups.google.com/forum/#!topic/lasagne-users/kRlgOrGQOH4
    - NOTE: gaussian blur looks broken - looks like a mean blur
- hessian free optimization
  - https://github.com/boulanni/theano-hf/blob/master/hf.py
- https://github.com/vitruvianscience/OpenDeep
  - custom decay functions
    - https://github.com/vitruvianscience/OpenDeep/blob/master/opendeep/utils/decay.py
- downhill
  - https://github.com/lmjohns3/downhill
  - http://downhill.readthedocs.org/en/stable/
  - lots of optimization algorithms implemented
    - eg. ESGD
- theanets
  - https://github.com/lmjohns3/theanets
  - http://theanets.readthedocs.org/en/latest/reference.html
  - same person as downhill
  - has a lots of implemented stuff
- CTC layer
  - https://github.com/rakeshvar/rnn_ctc/blob/master/ctc.py
  - https://github.com/shawntan/rnn-experiment/blob/master/CTC.ipynb
  - https://github.com/skaae/Lasagne-CTC
    - lasagne implementation
    - seems to be untested-ish
    - based on: https://github.com/mohammadpz/CTC-Connectionist-Temporal-Classification
** canopy
- monitor features
  - ability to save settings to localstorage / cookie
  - allowing line styles
    - ie.
      - dotted lines
        - http://www.d3noob.org/2013/01/making-dashed-line-in-d3js.html
      - not just circles
  - exluding values outside of boundaries
  - choosing plot type
    - box plot
    - mean
    - raw data
  - smarter min/max values
    - eg. 95-th percentile
  - rolling median?
  - ways of answering the question "what is the best $OBJECTIVE in < $TIME"
    - maybe some smart filtering on each axis with summary stats
      - eg. min, 95% percentile, etc.
- transforms
  - make transforms work for nodes on their own
  - remove_ancestors transform
    - replaces entire tree with given node
- do we want canopy to be able to control ordering of the data?
  - this would allow certain patterns
    - eg.
      - manipulating class balance
      - annealing class ratio / weight
      - changing sampling weight
        - eg. AW-SGD
      - storing metadata about each datapoint
        - eg.
          - for resampling
          - for curriculum learning
          - for storing gradient information
            - eg. SFO
  - this would also allow canopy to make data point sampling controllable by handlers
    - eg. if thawing an old model, can also thaw the state of the data
  - issues
    - evaluating all of the data can be expensive (eg. preprocessing images), impossible (eg. infinite dataset), or undesirable to store in RAM (eg. images)
  - alternatives
    - split the dataset generation process into 2 parts?
      - eg. generate metadata, generate data from metadata
    - allow the workflow to take in data (like normal), create an object as the data that lazy evaluates the necessary fields
      - eg. LazyImage["image"] calls a function to create the image
    - abstraction over data that allows manipulation
      - eg. DatasetContainer.sample(weights=weights)
- should adding costs could be a canopy-level concern?
  - use cases
    - eg.
      - all losses could be auxiliary losses
      - provide a list of nodes to add DSN to
  - pros
    - removes a lot of cost forwarding ugliness
    - could also handle optimizers and which nodes to apply them to
    - could have a default "main" cost
  - cons:
    - adds a lot of magic
- workflows / hooks
  - training
  - distillation
    - input: network1, outputkey1, network2, outputkey2, data generator
  - distillation from caffe model
  - resuming an in-training model
  - optionally resuming an in-training model, or restarting
  - printing progressbar after each epoch
  - checkpoint model every x batches / chunks
  - dynamically changing network during training to things that should be easy in canopy
    - eg. adding additional losses
  - test on validation set every x chunks
  - visualization
    - print filters
    - find most similar inputs to input
      - given:
        - query input
        - possible inputs
        - layer for representation to use
    - given a certain unit, find which inputs fire hardest
    - find inputs that are the most wrong
    - find input in training set that maximally activates a unit
    - find input that maximally activates for class (a unit)
      - with constant norm or L1/L2 loss
    - histogram of values of a tensor
      - eg. output of a layer
      - eg. gradient of a weight
    - image visualizations
      - show filter activations for given images
      - show grad(image_class, input)
        - behaves like importance map
      - show input patch that maximally activates a conv neuron
      - given mean image, maximize class score - L2 norm
      - deconvolutional networks
      - occlusion heatmap
    - saving learning curves
    - post-training report
      - eg. examples which are the most wrong
    - making a gif of pixelwise loss / heatmap / attention over time
    - images on low-dimensional (2D) space
      - with t-sne / PCA
      - using embedding from a certain layer
    - http://cs231n.github.io/understanding-cnn/
    - http://people.csail.mit.edu/torralba/research/drawCNN/drawNet.html
  - monitoring
    - printing out certain values
      - eg. loss
      - eg. average magnitude of gradient
    - alerting on certain conditions
      - eg. nan's or inf's
      - eg. magnitude of gradient/weight matrix too high
    - relationships between variables
    - logging batch normalization mean/variance updates
    - logging how close rolling BN mean/variance is to actual mean/variance
  - AUC / accuracy logging
  - saving model
  - hyperparameter optimization (hyperopt)
  - active learning
  - restarting training from a certain point
    - issue: dataset state won't be kept
  - q learning
  - curriculum learning
    - from the data point of view (ie. changing data distribution)
  - experience replay for hard-ish negatives
  - early stopping
  - hyperparameter annealing
    - eg.
      - dropout
      - learning rate
      - the weight of a loss function
  - sliding window application
  - approximate sliding window apply
    - eg. SPPnet
  - attaching preprocessing to a model
    - rationale: so that a serialized model can have preprocessing built in
  - chunking batches together
    - ratioanle: optimized GPU transfer
  - saving last x values of variables
  - auto-stop on nan
  - parameter hot-swapping
  - restarting from previous state w/ lower learning rate
  - using pre-trained networks
  - proper BN initialization
  - alternating training
    - between several models
  - adversarial training
  - hard negative mining
  - gradual hard negative mining
    - eg. facenet
  - serialization
    - both model & learning states (ie. states of the wrapper functions)
      - thus learning state must be serializable
      - should serialize all inner state
      - need hierarchical state for wrappers/hooks/workflows
  - net surgery
  - easily testing a new node
    - generate inputs / outputs / extra layers (eg. cost/updates/etc.)
  - run model on MNIST/CIFAR/etc.
  - localization
  - detection
  - segmentation
  - cascade of models
    - not necessarily trained jointly (?)
  - data augmentation
  - test time augmentation
  - ensembling
    - bagging
    - boosting
      - gradient boosting
      - adaboost
  - dynamic curriculum learning
    - saving mistaken examples for replaying
    - with metric learning
      - starting with easy values
  - polyak averaging
    - training hook?
- datasets
  - RNN
    - Blogger Dataset: http://www.cs.biu.ac.il/~koppel/blogs/blogs.zip (Age and gender data)
      - from https://github.com/IndicoDataSolutions/Passage
    - use MNIST, scan one vector at a time
      - https://github.com/IndicoDataSolutions/Passage/blob/master/examples/mnist.py
  - https://github.com/jaberg/skdata/wiki/Data-Set-Modules
- how to save state part-way through training
- workflow for batch norm test time stats
  - ie. compute layer-wise with fixed weights
    - need to do it on a topological sort of the DAG
- seems like a very reasonable assumption that training might involve arbitrary python code execution
  - eg. with deep q learning, might have to simulate a game
- live plotting/monitoring
  - other tools (blocks / opendeep) use bokeh
- visualization
  - http://deeplearning.net/tutorial/utilities.html
    - code to plot images/filters
** possible issues
- when freezing training state, dataset state won't be frozen
** future
- use metaclass for registering classes for serialization
  - see: https://github.com/lmjohns3/downhill/blob/master/downhill/util.py
- look into drawing network diagrams:
  - https://github.com/Lasagne/Lasagne/issues/174
    - https://github.com/ebenolson/Lasagne/blob/master/examples/draw_net.py
- javascript interface to expand nodes
  - more expanded = more low-level
- parallelism for running gpu networks on a different process
  - theano error (with forking after a cuda context is created)
    - https://groups.google.com/forum/#!topic/theano-users/Pu4YKlZKwm4
    - solution:
      - start an additional thread initially to run all cuda stuff
        - https://gist.github.com/albertz/4177e40d41cb7f9f7c68
        - advantage:
          - can use multiple GPUs
- think about:
  - recursive NN
  - RNN
    - beam search
    - bidirectional
    - nested recurrence
      - eg. scan in scan (like a non-fixed size ReNet)
    - attentional models
      - look into attentional interfaces
        - https://github.com/bartvm/blocks/blob/master/blocks/bricks/attention.py
